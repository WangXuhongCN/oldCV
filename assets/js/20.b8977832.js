(window.webpackJsonp=window.webpackJsonp||[]).push([[20],{267:function(e,n,t){"use strict";t.r(n);var r=t(0),a=Object(r.a)({},function(){var e=this,n=e.$createElement,t=e._self._c||n;return t("div",{staticClass:"content"},[t("MarkdownCard",{attrs:{image:"/ME.jpg"}},[t("h1",{attrs:{id:"xuhong-wang"}},[e._v("Xuhong Wang")]),e._v(" "),t("p",[e._v("Ph.D. Candidate at Shanghai Jiao Tong University.")]),e._v(" "),t("p",[t("a",{attrs:{href:"https://github.com/wangxuhongcn",target:"_blank",rel:"noopener noreferrer"}},[e._v("Github"),t("img",{attrs:{src:"/icons/github.svg",width:"20"}}),t("OutboundLink")],1),e._v(" "),t("a",{attrs:{href:"https://www.linkedin.com/in/xuhong-wang/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Linkedin"),t("img",{attrs:{src:"/icons/linkedin.svg",width:"20"}}),t("OutboundLink")],1),e._v(" "),t("a",{attrs:{href:"https://www.zhihu.com/people/wang-xu-hong-49",target:"_blank",rel:"noopener noreferrer"}},[e._v("Zhihu"),t("img",{attrs:{src:"/icons/zhihu.jpg",width:"20"}}),t("OutboundLink")],1),e._v(" "),t("a",{attrs:{href:"https://scholar.google.com/citations?user=qBfqJbcAAAAJ&hl=en",target:"_blank",rel:"noopener noreferrer"}},[e._v("Google Scholar"),t("img",{attrs:{src:"/icons/GS.png",width:"20"}}),t("OutboundLink")],1),e._v(" "),t("a",{attrs:{href:"https://github.com/eleboss/eleboss.github.io/raw/master/CV.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("My CV"),t("OutboundLink")],1)]),e._v(" "),t("p",[e._v("E-mail: wang_xuhong@sjtu.edu.cn")])]),e._v(" "),t("h2",{attrs:{id:"about-me"}},[e._v("About me")]),e._v(" "),t("p",[e._v("I am currently a 3rd-year PhD candidate at "),t("a",{attrs:{href:"http://english.seiee.sjtu.edu.cn/",target:"_blank",rel:"noopener noreferrer"}},[e._v("School of Electronic Information and Electrical Engineering"),t("OutboundLink")],1),e._v(", "),t("a",{attrs:{href:"http://en.sjtu.edu.cn/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Shanghai Jiao Tong University"),t("OutboundLink")],1),e._v(", advised by Prof. "),t("a",{attrs:{href:"http://automation.sjtu.edu.cn/en/ShowPeople.aspx?info_id=374&info_lb=326&flag=224",target:"_blank",rel:"noopener noreferrer"}},[e._v("Yupu Yang"),t("OutboundLink")],1),e._v(". I acquired my bachelor degree from "),t("a",{attrs:{href:"http://www.scu.edu.cn/eneieen",target:"_blank",rel:"noopener noreferrer"}},[e._v("School of Electronics and Information Engineering"),t("OutboundLink")],1),e._v(", "),t("a",{attrs:{href:"http://en.scu.edu.cn/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Sichuan University"),t("OutboundLink")],1),e._v(" in 2017.")]),e._v(" "),t("p",[e._v("My research lies at applying variational inference, (graph) neural networks and anomaly detection techniques to cyber-physical systems and industrial complex networks.")]),e._v(" "),t("h2",{attrs:{id:"news"}},[e._v("News")]),e._v(" "),t("ul",[t("li",[e._v("[Feb. 2020] Accepted an exchange student invitation letter from "),t("a",{attrs:{href:"https://www.berkeley.edu/",target:"_blank",rel:"noopener noreferrer"}},[e._v("UC Berkeley"),t("OutboundLink")],1),e._v(" Prof. "),t("a",{attrs:{href:"https://www2.eecs.berkeley.edu/Faculty/Homepages/sangiovanni-vicentelli.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("Alberto Sangiovanni Vincentelli"),t("OutboundLink")],1),e._v(".")]),e._v(" "),t("li",[e._v("[Jan. 2020] "),t("a",{attrs:{href:"https://www.janestreet.com/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Jane Street"),t("OutboundLink")],1),e._v(" Quantitative Trading Winter Camp, HKG.")]),e._v(" "),t("li",[e._v("[Nov. 2019] "),t("a",{attrs:{href:"https://authors.elsevier.com/a/1aXQK3OAb8x1v3",target:"_blank",rel:"noopener noreferrer"}},[e._v("One paper"),t("OutboundLink")],1),e._v(" accepted by "),t("em",[e._v("Knowledge-Based Systems")]),e._v(".")]),e._v(" "),t("li",[e._v("[Oct. 2019] Awarded the SJTU PhD Academic Scholarship (8000 CNY).")])]),e._v(" "),t("h2",{attrs:{id:"education"}},[e._v("Education")]),e._v(" "),e._m(0),e._v(" "),t("h2",{attrs:{id:"publication"}},[e._v("Publication")]),e._v(" "),t("h3",{attrs:{id:"paper"}},[e._v("Paper")]),e._v(" "),t("ol",[t("li",[t("strong",[e._v("S. Lin")]),e._v(', F. Xu, X. Wang, W. Yang, L. Yu. "Efficient Spatial-Temporal Normalization of SAE Representation for Event Camera." '),t("em",[e._v("IEEE Robotics and Automation Letters (RA-L)")]),e._v(", under review. ["),t("a",{attrs:{href:"https://github.com/eleboss/chain",target:"_blank",rel:"noopener noreferrer"}},[e._v("Code"),t("OutboundLink")],1),e._v("] ["),t("a",{attrs:{href:"https://github.com/eleboss/eleboss.github.io/blob/master/nor.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("Preprint"),t("OutboundLink")],1),e._v("]")]),e._v(" "),t("li",[t("strong",[e._v("S. Lin")]),e._v('*, J. Wang*, R. Peng, W. Yang (2019). "Development of an Autonomous Unmanned Aerial Manipulator Based on a Real-Time Oriented-Object Detection Method." '),t("em",[e._v("Sensors")]),e._v(" (IF: 3.302), "),t("em",[e._v("19")]),e._v("(10), 2396. ["),t("a",{attrs:{href:"https://www.mdpi.com/1424-8220/19/10/2396",target:"_blank",rel:"noopener noreferrer"}},[e._v("Paper"),t("OutboundLink")],1),e._v("]")]),e._v(" "),e._m(1),e._v(" "),t("li",[e._v("H. Yu, "),t("strong",[e._v("S. Lin")]),e._v(', J. Wang, K. Fu, W. Yang. "An Intelligent Unmanned Aircraft System for Wilderness Search and Rescue." '),t("em",[e._v("International Micro Air Vehicles Conference and Flight Competition (IMAV)")]),e._v(", 2017, "),t("strong",[e._v("oral")]),e._v(". ["),t("a",{attrs:{href:"http://www.imavs.org/papers/2017/143_imav2017_proceedings.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("Paper"),t("OutboundLink")],1),e._v("]\n")]),e._v(" "),t("li",[e._v("X. Wang, Y. Du, "),t("strong",[e._v("S. Lin")]),e._v(', P. Cui, Y. Shen, Y. Yang.  "adVAE: a Self-adversarial Variational Autoencoder with Gaussian Anomaly Prior Knowledge for Anomaly Detection." '),t("em",[e._v("Knowledge-Based Systems")]),e._v(", accept. ["),t("a",{attrs:{href:"https://arxiv.org/abs/1903.00904",target:"_blank",rel:"noopener noreferrer"}},[e._v("Preprint"),t("OutboundLink")],1),e._v("]")]),e._v(" "),e._m(2)]),e._v(" "),t("h3",{attrs:{id:"patent-selected"}},[e._v("Patent (Selected)")]),e._v(" "),e._m(3),e._v(" "),t("h2",{attrs:{id:"experiences"}},[e._v("Experiences")]),e._v(" "),e._m(4),e._v(" "),t("h2",{attrs:{id:"awards-honors"}},[e._v("Awards & Honors")]),e._v(" "),t("h3",{attrs:{id:"scholarship"}},[e._v("Scholarship")]),e._v(" "),e._m(5),e._v(" "),t("h3",{attrs:{id:"contest"}},[e._v("Contest")]),e._v(" "),e._m(6),e._v(" "),t("h3",{attrs:{id:"activity"}},[e._v("Activity")]),e._v(" "),e._m(7),e._v(" "),t("h2",{attrs:{id:"selected-works-more"}},[e._v("Selected Works "),t("sub",[t("sup",[e._v("["),t("a",{attrs:{href:"https://eleboss.github.io/projects/",target:"_blank",rel:"noopener noreferrer"}},[e._v("more"),t("OutboundLink")],1),e._v("]")])])]),e._v(" "),t("MarkdownCard",{attrs:{image:"/projects/EBIR.jpg"}},[t("p",[t("strong",[e._v("Cross-Modal Matching Between Neuromorphic Events and Color Images via Adversarial Learning")])]),e._v(" "),t("p",[e._v("In this paper, we propose the Event-Based Image Retrieval (EBIR) task. Given an event stream depicting a particular object as query, the aim is to retrieve color images containing the same object that may be captured under different views, backgrounds, or with occlusions. We address the EBIR task by formulating an EBIR framework to jointly model neuromorphic events and color images into a common embedding space, where adversarial learning is used to align the feature distributions of the two modalities of data in the embedding space. We also contribute to the community the first EBIR dataset EC180 with 180 objects, where each object has an event stream and five color images.")])]),e._v(" "),t("MarkdownCard",{attrs:{image:"/projects/normalization.png"}},[t("p",[t("strong",[e._v("Efficient Spatial-Temporal Normalization of SAE Representation for Event Camera")])]),e._v(" "),t("p",[e._v("In this work, we proposed a highly efficient normalization method named chain normalization and an improved ordering strategy. By embedding the inherent nature of SAE, our method can not only run fast but also reach the highest performance without manual parameter tuning. In the experiments, our algorithm can run significantly faster than the previous methods. To further validate the normalized results, we conduct object recognition experiments on two large event-based open datasets. Experimental results show that our method achieves the highest classification accuracy among other normalization methods.")]),e._v(" "),t("p",[e._v("["),t("a",{attrs:{href:"https://github.com/eleboss/chain",target:"_blank",rel:"noopener noreferrer"}},[e._v("Code"),t("OutboundLink")],1),e._v("] ["),t("a",{attrs:{href:"https://github.com/eleboss/eleboss.github.io/blob/master/nor.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("Preprint"),t("OutboundLink")],1),e._v("]")])]),e._v(" "),t("MarkdownCard",{attrs:{image:"/projects/grasping.png"}},[t("p",[t("strong",[e._v("Toward Autonomous Rotation-Aware Unmanned Aerial Grasping")])]),e._v(" "),t("p",[t("strong",[e._v("S. Lin")]),e._v(", J. Wang, R. Peng, W. Yang.")]),e._v(" "),t("p",[e._v("In this work, we developed a vision-based autonomous UAM with a 3DoF robotic arm for rotational grasping and with a displacement compensation system for compensating the center of gravity. And we proposed a novel detection approach called Rotation-SqueezeDet to enable rotation-aware grasping, which can give the target position and rotation angle in near real-time on Jetson TX2.")]),e._v(" "),t("p",[e._v("["),t("a",{attrs:{href:"https://github.com/eleboss/UAMmech",target:"_blank",rel:"noopener noreferrer"}},[e._v("Open-hardware"),t("OutboundLink")],1),e._v("] ["),t("a",{attrs:{href:"https://www.mdpi.com/1424-8220/19/10/2396",target:"_blank",rel:"noopener noreferrer"}},[e._v("Paper"),t("OutboundLink")],1),e._v("]")])]),e._v(" "),t("MarkdownCard",{attrs:{image:"/icra.jpg"}},[t("p",[t("strong",[e._v("ICRA2018 DJI Robomaster AI Challenge")])]),e._v(" "),t("p",[e._v("W. He, "),t("strong",[e._v("S. Lin")]),e._v(", Q. Cui, R. Peng, J. Wang, H. Yu.")]),e._v(" "),t("p",[e._v("The ICRA 2018 DJI RoboMaster AI Challenge requires robots to drive and launch projectiles using artificial intelligence related technologies. Each team is required to build up to TWO autonomous AI robots to compete in a 5m Ã— 8m arena filled with various obstacles. To win, a team must defeat TWO AI robots presented by the RoboMaster Organizing Committee.")]),e._v(" "),t("p",[e._v("We won the "),t("strong",[e._v("Finalist Prize, Global Rank:6/70")]),e._v(" of "),t("a",{attrs:{href:"https://www.robomaster.com/en-US/robo/icra",target:"_blank",rel:"noopener noreferrer"}},[e._v("ICRA2018 DJI Robomaster AI Challenge"),t("OutboundLink")],1)]),e._v(" "),t("p",[e._v("Tech: "),t("em",[e._v("ROS, C++, Python, Tensorflow, Solidworks, Embedded Programming")])])]),e._v(" "),t("MarkdownCard",{attrs:{image:"/projects/tunneldrone.png"}},[t("p",[t("strong",[e._v("Development of an Intelligent Unmanned Aircraft System for Tunnel Inspection (thesis, in progress)")])]),e._v(" "),t("p",[e._v("In this work, I developed a tunnel inspection system based on Pixhawk4 and DJI M100 drone. I Employed point cloud filters and RANSAC line fitting for tunnel perception. And I employed VINS-Mono for localization. With several lab members, I successfully conducted multiple autonomous inspections in the 280-meter long Luojia Shan tunnel.")])]),e._v(" "),t("MarkdownCard",{attrs:{image:"/projects/deeptunnel.jpg"}},[t("p",[t("strong",[e._v("End-to-end Tunnel Perception (in progress)")])]),e._v(" "),t("p",[e._v("Planning to develop an end-to-end tunnel perception algorithm using the event camera.")])]),e._v(" "),t("MarkdownCard",{attrs:{image:"/projects/wisar.png"}},[t("p",[t("strong",[e._v("An Intelligent Unmanned Aircraft System for Wilderness Search and Rescue")])]),e._v(" "),t("p",[e._v("H. Yu, "),t("strong",[e._v("S. Lin")]),e._v(", J. Wang, K. Fu, W. Yang.")]),e._v(" "),t("p",[e._v("In this work, we developed a wilderness search and rescue (WiSAR) system based on DJI M100 Unmanned Aerial Vehicle (UAV) and a ground station to search and rescue the survivors in wild. We combined infrared and optical target detection to increase the detection speed and accuracy. And we used multiple sensors to make this system can autonomous avoiding obstructions and landing on mobile platform. To increase the detection accuracy of SSD, we adopted ResNet-101 as the base net. And trained it on the UAV-PP dataset. The actual flying test have been conducted in multiple situations to verify the feasibility of our WiSAR system. Paper accepted by "),t("em",[e._v("IMAV")]),e._v(" and method has been granted a patent.")]),e._v(" "),t("p",[e._v("["),t("a",{attrs:{href:"http://www.imavs.org/papers/2017/143_imav2017_proceedings.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("Paper"),t("OutboundLink")],1),e._v("]")])])],1)},[function(){var e=this,n=e.$createElement,t=e._self._c||n;return t("ul",[t("li",[t("strong",[e._v("School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China")]),t("br"),e._v("\nSep. 2017 -- Present")]),e._v(" "),t("li",[t("strong",[e._v("Exchange Student, Mita Campus, Keio University, Tokyo, Japan")]),t("br"),e._v("\nFeb. 2017. The international center.")]),e._v(" "),t("li",[t("strong",[e._v("School of Electronics and Information Engineering, Sichuan University, Chengdu, China")]),t("br"),e._v("\nSep. 2013 -- Jul. 2017")])])},function(){var e=this.$createElement,n=this._self._c||e;return n("li",[this._v("F. Xu*, "),n("strong",[this._v("S. Lin")]),this._v('*, et al. "Matching Neuromorphic Events and Color Images via Adversarial Learning." 2020 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), under review.')])},function(){var e=this.$createElement,n=this._self._c||e;return n("li",[this._v("F. Xu, W. Yang, "),n("strong",[this._v("S. Lin")]),this._v(', H. Luo, G. Xia "Mental Retrieval of Remote Sensing Images via Adversarial Sketch-Image Feature Learning."  '),n("em",[this._v("IEEE Transactions on Geoscience and Remote Sensing")]),this._v(", under review.")])},function(){var e=this,n=e.$createElement,t=e._self._c||n;return t("ol",[t("li",[t("strong",[e._v("S. Lin")]),e._v(", W. He, H. Yu, W. Yang. A Multifunctional Unmanned Aerial Vehicle for Field Search and Rescue, CN206926823U, Jul. 2017.")]),e._v(" "),t("li",[t("strong",[e._v("S. Lin")]),e._v(", H. Zhao, F. Jiang, P. Xue, S. Li, Z. Guo. A Dot Matrix Braille Touch Screen, CN106775123A, Jan. 2017.")]),e._v(" "),t("li",[e._v("J. Huang, X. Wang, "),t("strong",[e._v("S. Lin")]),e._v(", H. Zhao, Z. Hu. A Pull-type Braille Screen and its Components Reuse Method, CN106781881A, Jan. 2017.")])])},function(){var e=this,n=e.$createElement,t=e._self._c||n;return t("ul",[t("li",[e._v("Attend the "),t("strong",[e._v("2019 EE HKPFS Summer School of City University of Hong Kong")]),e._v(", Jul. 2019")]),e._v(" "),t("li",[e._v("Attend the "),t("strong",[e._v("Summer School of Simultaneous Localization and Mapping(SLAM)")]),e._v(" held by CAD&CG State Key Lab, Zhejiang University. Zhejiang, China, Jul. 2018.")]),e._v(" "),t("li",[e._v("Attend the "),t("strong",[e._v("2018 IEEE International Conference on Robotics and Automation (ICRA)")]),e._v(" and "),t("strong",[e._v("Workshop of Aerial Robotic Inspection and Maintenance: Research Challenges, Field Experience and Industry Needs")]),e._v(", Brisbane, Australia, May. 2018.")]),e._v(" "),t("li",[e._v("Attend the "),t("strong",[e._v("9th International Micro Air Vehicles Conference")]),e._v(", Toulouse, France, Sep. 2018.")]),e._v(" "),t("li",[e._v("Attend the "),t("strong",[e._v("Seminar of Frontier Deep Learning Research")]),e._v(" held by China Computer Federation. Hubei, China, Nov. 2017.")])])},function(){var e=this,n=e.$createElement,t=e._self._c||n;return t("ul",[t("li",[t("strong",[e._v("National Scholarship for Postgraduate")]),e._v(", Oct. 2018 ("),t("strong",[e._v("TOP 1%")]),e._v(")")]),e._v(" "),t("li",[t("strong",[e._v("1"),t("sup",[e._v("st")]),e._v(" Prize")]),e._v(", Postgraduate Academic Scholarship of Wuhan University, Sep. 2018 ("),t("strong",[e._v("TOP 5%")]),e._v(")")]),e._v(" "),t("li",[t("strong",[e._v("1"),t("sup",[e._v("st")]),e._v(" Prize")]),e._v(", Postgraduate Academic Scholarship of Wuhan University, Sep. 2017 ("),t("strong",[e._v("TOP 5%")]),e._v(")")]),e._v(" "),t("li",[t("strong",[e._v("1"),t("sup",[e._v("st")]),e._v(" Prize")]),e._v(", Postgraduate Entrance Scholarship of Wuhan University, Oct. 2017 ("),t("strong",[e._v("TOP 5%")]),e._v(")")]),e._v(" "),t("li",[t("strong",[e._v("1"),t("sup",[e._v("st")]),e._v(" Prize")]),e._v(", Outstanding Scholarship of Sichuan University, Oct. 2016 ("),t("strong",[e._v("TOP 5%")]),e._v(")")]),e._v(" "),t("li",[t("strong",[e._v("1"),t("sup",[e._v("st")]),e._v(" Prize")]),e._v(", Individual Scholarship of Sichuan University, Nov. 2015 ("),t("strong",[e._v("TOP 8%")]),e._v(")")]),e._v(" "),t("li",[t("strong",[e._v("2"),t("sup",[e._v("nd")]),e._v(" Prize")]),e._v(", Individual Scholarship of Sichuan University, Nov. 2014 ("),t("strong",[e._v("TOP 10%")]),e._v(")")])])},function(){var e=this,n=e.$createElement,t=e._self._c||n;return t("ul",[t("li",[t("strong",[e._v("1"),t("sup",[e._v("st")]),e._v(" Prize")]),e._v(" & "),t("strong",[e._v("Best paper")]),e._v(", National Postgraduate Electronic Design Competition, Aug. 2018 ("),t("strong",[e._v("National Rank: 5/2437, TOP 0.2%")]),e._v(")")]),e._v(" "),t("li",[t("strong",[e._v("Finalist Prize")]),e._v(", ICRA2018 DJI Robomaster AI Challenge, May. 2018 ("),t("strong",[e._v("Global Rank: 6/70")]),e._v(")")]),e._v(" "),t("li",[t("strong",[e._v("Finalist Prize")]),e._v(", DJI Robomaster Aerial Robot Challenge, May. 2017")]),e._v(" "),t("li",[t("strong",[e._v("1"),t("sup",[e._v("st")]),e._v(" Prize")]),e._v(", Microsoft Imagine Cup 2016 Global Students Technology Competition (China Round), Apr. 2016 ("),t("strong",[e._v("TOP 1%")]),e._v(")")]),e._v(" "),t("li",[t("strong",[e._v("1"),t("sup",[e._v("st")]),e._v(" Prize")]),e._v(", National Undergraduate Electronic Design Competition, Aug. 2015 ("),t("strong",[e._v("TOP 1%")]),e._v(")")])])},function(){var e=this,n=e.$createElement,t=e._self._c||n;return t("ul",[t("li",[e._v("Excellent Postgraduate Student of Wuhan University, Dec. 2018")]),e._v(" "),t("li",[e._v("Excellent Undergraduate Thesis of Sichuan University, Jun. 2017")]),e._v(" "),t("li",[e._v("Excellent Student Cadre of Sichuan University, Nov. 2015")]),e._v(" "),t("li",[e._v("Outstanding Academic Student Group Leader of Sichuan University, Jul. 2015")]),e._v(" "),t("li",[e._v("Excellent Student Cadre of Sichuan University, Nov. 2014")]),e._v(" "),t("li",[e._v("Outstanding Academic Student Group Leader of Sichuan University, Jul. 2014")])])}],!1,null,null,null);n.default=a.exports}}]);